{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the fruit group project As disclaimer, the full documents and data are stored in the following repository. Documentation Data and Code A virtual demonstration of the application Since in this form of documentation we can show a video, but not a real application, we have prepared just that. The video should simulate the process of shopping in a supermarket. We deliberately paid attention to the sequence of movements and the direction in which the products are passed. The Project: Grocery Vision Grocery Vision is a computer vision application that simplifies the grocery checkout process. What does \"simpler\" mean? By simpler, we mean that users don't have to scan labels or memorize PLU codes. We believe that computer vision, or more specifically object recognition in this process, can be a solution to this problem because it provides a real-time way to recognize objects in a variety that humans can only achieve after a long training period. However, in natural products such as in the fruit and vegetable department, there are also different shapes and colors, all of which can be assigned to one class and one product. There is a standard that must be followed to sell them as one product, but there remain natural differences between each fruit. Nevertheless, we have chosen this application for our Grocery Vision project. To clarify the \"we\" briefly, we are 5 students from KIT who have a great interest in Data Science and software applications. That's why we all signed up for the AISS Applied in Computer Vision course and had a lot of fun together. We introduce ourselves a bit more detailed here. In our application, we wanted to simplify the checkout process for products that need to be weighed. Our solution starts at the checkout. As you can see in the image, we use a camera that films a live video of the checkout. Using the neural network previously trained on synthetic data, our application automatically recognizes the items and lists them on the screen. The prices from the system are then assigned to the products and processed into the total after the purchase is complete. Summary of benefits: easier shopping for supermarket customers, shorter training period for new store employees. And POS system providers can offer a centralized solution for weighing and automatic product recognition.","title":"Home"},{"location":"#welcome-to-the-fruit-group-project","text":"As disclaimer, the full documents and data are stored in the following repository. Documentation Data and Code","title":"Welcome to the fruit group project"},{"location":"#a-virtual-demonstration-of-the-application","text":"Since in this form of documentation we can show a video, but not a real application, we have prepared just that. The video should simulate the process of shopping in a supermarket. We deliberately paid attention to the sequence of movements and the direction in which the products are passed.","title":"A virtual demonstration of the application"},{"location":"#the-project-grocery-vision","text":"Grocery Vision is a computer vision application that simplifies the grocery checkout process. What does \"simpler\" mean? By simpler, we mean that users don't have to scan labels or memorize PLU codes. We believe that computer vision, or more specifically object recognition in this process, can be a solution to this problem because it provides a real-time way to recognize objects in a variety that humans can only achieve after a long training period. However, in natural products such as in the fruit and vegetable department, there are also different shapes and colors, all of which can be assigned to one class and one product. There is a standard that must be followed to sell them as one product, but there remain natural differences between each fruit. Nevertheless, we have chosen this application for our Grocery Vision project. To clarify the \"we\" briefly, we are 5 students from KIT who have a great interest in Data Science and software applications. That's why we all signed up for the AISS Applied in Computer Vision course and had a lot of fun together. We introduce ourselves a bit more detailed here. In our application, we wanted to simplify the checkout process for products that need to be weighed. Our solution starts at the checkout. As you can see in the image, we use a camera that films a live video of the checkout. Using the neural network previously trained on synthetic data, our application automatically recognizes the items and lists them on the screen. The prices from the system are then assigned to the products and processed into the total after the purchase is complete. Summary of benefits: easier shopping for supermarket customers, shorter training period for new store employees. And POS system providers can offer a centralized solution for weighing and automatic product recognition.","title":"The Project: Grocery Vision"},{"location":"all/","text":"cashiers of tomorrow Grocery Vision is a computer vision application that simplifies the grocery checkout process. What does \"simpler\" mean? By simpler, we mean that users don't have to scan labels or memorize PLU codes. We believe that computer vision, or more specifically object recognition in this process, can be a solution to this problem because it provides a real-time way to recognize objects in a variety that humans can only achieve after a long training period. However, in natural products such as in the fruit and vegetable department, there are also different shapes and colors, all of which can be assigned to one class and one product. There is a standard that must be followed to sell them as one product, but there remain natural differences between each fruit. Nevertheless, we have chosen this application for our Grocery Vision project. To clarify the \"we\" briefly, we are 5 students from KIT who have a great interest in Data Science and software applications. That's why we all signed up for the AISS Applied in Computer Vision course and had a lot of fun together. We introduce ourselves a bit more detailed here. In our application, we wanted to simplify the checkout process for products that need to be weighed. Our solution starts at the checkout. As you can see in the image, we use a camera that films a live video of the checkout. Using the neural network previously trained on synthetic data, our application automatically recognizes the items and lists them on the screen. The prices from the system are then assigned to the products and processed into the total after the purchase is complete. Summary of benefits: easier shopping for supermarket customers, shorter training period for new store employees. And POS system providers can offer a centralized solution for weighing and automatic product recognition. 1. 1. 1.","title":"All"},{"location":"all/#cashiers-of-tomorrow","text":"","title":"cashiers of tomorrow"},{"location":"all/#_1","text":"Grocery Vision is a computer vision application that simplifies the grocery checkout process. What does \"simpler\" mean? By simpler, we mean that users don't have to scan labels or memorize PLU codes. We believe that computer vision, or more specifically object recognition in this process, can be a solution to this problem because it provides a real-time way to recognize objects in a variety that humans can only achieve after a long training period. However, in natural products such as in the fruit and vegetable department, there are also different shapes and colors, all of which can be assigned to one class and one product. There is a standard that must be followed to sell them as one product, but there remain natural differences between each fruit. Nevertheless, we have chosen this application for our Grocery Vision project. To clarify the \"we\" briefly, we are 5 students from KIT who have a great interest in Data Science and software applications. That's why we all signed up for the AISS Applied in Computer Vision course and had a lot of fun together. We introduce ourselves a bit more detailed here. In our application, we wanted to simplify the checkout process for products that need to be weighed. Our solution starts at the checkout. As you can see in the image, we use a camera that films a live video of the checkout. Using the neural network previously trained on synthetic data, our application automatically recognizes the items and lists them on the screen. The prices from the system are then assigned to the products and processed into the total after the purchase is complete. Summary of benefits: easier shopping for supermarket customers, shorter training period for new store employees. And POS system providers can offer a centralized solution for weighing and automatic product recognition. 1. 1. 1.","title":""},{"location":"architecture/","text":"Technical Implementation Overview As mentioned in the former section, we used the YoloV5 architecture for our object detection task. We utilized the comprehensive repository from [ultralytics](https://studentkit.sharepoint.com/sites/AISS-AICV/Freigegebene%20Dokumente/General/(https:/github.com/ultralytics/yolov5), which already provided the necessary tools to get us started. As this repository used PyTorch, this was a key dependency for us. Furthermore, to get the video stream from the CSI-camera from the Jetson Nano we used a combination of Gstreamer and OpenCV, which allowed us to run our inference with Yolo framework on each recorded frame. In order to present the respective results, the frame that was used for inference was augmented with the bounding boxes around the detected objects with the respective classes and scores. As this detection was only one part of our solution, we passed the augmented frame to a webpage where our results were presented in a user-friendly frontend, which was built using JavaScript and Bootstrap. The communication between the Python backend and the webpage was managed by a combination of Flask and SocketIO. Figure 6: Techstack Furthermore, we speed up our inference time using the ONNX runtime engine. An overview of our techstack is summarized in Figure 6 Inference time optimization We first started out using vanilla PyTorch on the CPU for our inference, which turned out to be rather slow as the inference time for one image already took 0,5 seconds, so we could only run our videostream at 1 Frame per second (FPS). As we already used the nano version of the yolo architecture, so the smallest version of the CNN available, we had to find other ways to improve our inference speed. The final solution that we came across was the ONNX runtime engine, an open-source project which is specifically designed to accelerate the machine learning process, in particular the inference step. We implemented the ONNX runtime engine by utilizing the yoloRT repository, which made it particularly easy to transform an already existing model in the PyTorch format to the ONNX format. The main simplification provided by this repository is that the transformation of the model format also respects changes that are necessary to use the inference using the ONNX runtime engine in a way that further augmentation of the results is not necessary, like preprocessing the shape of the processed image for a correct display of the bounding boxes. Using this solution, we were able to decrease the inference time by about 44%, from 500ms to 280ms. This allowed us to run our model on 3 FPS, which worked quite well for our solution. However, this solution still uses the CPU, as we had problems installing the required packages for our Python version with GPU support. The Jetson nano already comes preinstalled with the most used machine learning libraries, compiled with GPU support, however only for the preinstalled Python version 3.6.9. The repositories that we used required us to use Python 3.8 or higher, so we could not use the preinstalled packages in our environment. When we reinstalled the respective packages from PyPi, all of them only supported the CPU or had to recompiled from source with GPU support enabled. Figure 7: Inference time speed-up Regardless of these restrictions, with the help of group 2 we found a prebuilt Python wheel for the ONNX runtime engine with GPU support, which could be downloaded and easily installed into our environment. By utilizing the GPU, we could gain a massive improvement of again reducing our inference time by 78.5% down to 60ms, which allowed us to run our model 7FPS. A summary of the inference time improvements is shown in figure 7. Issues and Learnings Figure 8: Main compatibilityissues As in every project we came across multiple issues, however most of them can be summarized under \"Compatibility issues\". A short overview is given in figure 8. As mentioned in the last section, we had trouble installing the necessary packages with GPU support, since due to our dependencies we were required to use Python 3.8 or newer, however the preinstalled packages with GPU-support that came with the Jetson Nano could only be used with Python 3.6.9. If the packages were installed via pip, the corresponding packages only had CPU support. Moreover, at the beginning of our project we started developing a solution on our personal computers that accessed the webcam of a computer via JavaScript, however when we deployed the solution on the Nano, we realized that solution does not work, as the used CSI-Camera was not detected as a webcam. Since we did not find an appropriate solution to this problem, we had to start over with a new solution. The main learning we took from this is that we want to increase our use of OS agnostic software solution like Docker, in order to prevent these mistakes from happening again.","title":"Architecture"},{"location":"architecture/#technical-implementation","text":"","title":"Technical Implementation"},{"location":"architecture/#overview","text":"As mentioned in the former section, we used the YoloV5 architecture for our object detection task. We utilized the comprehensive repository from [ultralytics](https://studentkit.sharepoint.com/sites/AISS-AICV/Freigegebene%20Dokumente/General/(https:/github.com/ultralytics/yolov5), which already provided the necessary tools to get us started. As this repository used PyTorch, this was a key dependency for us. Furthermore, to get the video stream from the CSI-camera from the Jetson Nano we used a combination of Gstreamer and OpenCV, which allowed us to run our inference with Yolo framework on each recorded frame. In order to present the respective results, the frame that was used for inference was augmented with the bounding boxes around the detected objects with the respective classes and scores. As this detection was only one part of our solution, we passed the augmented frame to a webpage where our results were presented in a user-friendly frontend, which was built using JavaScript and Bootstrap. The communication between the Python backend and the webpage was managed by a combination of Flask and SocketIO. Figure 6: Techstack Furthermore, we speed up our inference time using the ONNX runtime engine. An overview of our techstack is summarized in Figure 6","title":"Overview"},{"location":"architecture/#inference-time-optimization","text":"We first started out using vanilla PyTorch on the CPU for our inference, which turned out to be rather slow as the inference time for one image already took 0,5 seconds, so we could only run our videostream at 1 Frame per second (FPS). As we already used the nano version of the yolo architecture, so the smallest version of the CNN available, we had to find other ways to improve our inference speed. The final solution that we came across was the ONNX runtime engine, an open-source project which is specifically designed to accelerate the machine learning process, in particular the inference step. We implemented the ONNX runtime engine by utilizing the yoloRT repository, which made it particularly easy to transform an already existing model in the PyTorch format to the ONNX format. The main simplification provided by this repository is that the transformation of the model format also respects changes that are necessary to use the inference using the ONNX runtime engine in a way that further augmentation of the results is not necessary, like preprocessing the shape of the processed image for a correct display of the bounding boxes. Using this solution, we were able to decrease the inference time by about 44%, from 500ms to 280ms. This allowed us to run our model on 3 FPS, which worked quite well for our solution. However, this solution still uses the CPU, as we had problems installing the required packages for our Python version with GPU support. The Jetson nano already comes preinstalled with the most used machine learning libraries, compiled with GPU support, however only for the preinstalled Python version 3.6.9. The repositories that we used required us to use Python 3.8 or higher, so we could not use the preinstalled packages in our environment. When we reinstalled the respective packages from PyPi, all of them only supported the CPU or had to recompiled from source with GPU support enabled. Figure 7: Inference time speed-up Regardless of these restrictions, with the help of group 2 we found a prebuilt Python wheel for the ONNX runtime engine with GPU support, which could be downloaded and easily installed into our environment. By utilizing the GPU, we could gain a massive improvement of again reducing our inference time by 78.5% down to 60ms, which allowed us to run our model 7FPS. A summary of the inference time improvements is shown in figure 7.","title":"Inference time optimization"},{"location":"architecture/#issues-and-learnings","text":"Figure 8: Main compatibilityissues As in every project we came across multiple issues, however most of them can be summarized under \"Compatibility issues\". A short overview is given in figure 8. As mentioned in the last section, we had trouble installing the necessary packages with GPU support, since due to our dependencies we were required to use Python 3.8 or newer, however the preinstalled packages with GPU-support that came with the Jetson Nano could only be used with Python 3.6.9. If the packages were installed via pip, the corresponding packages only had CPU support. Moreover, at the beginning of our project we started developing a solution on our personal computers that accessed the webcam of a computer via JavaScript, however when we deployed the solution on the Nano, we realized that solution does not work, as the used CSI-Camera was not detected as a webcam. Since we did not find an appropriate solution to this problem, we had to start over with a new solution. The main learning we took from this is that we want to increase our use of OS agnostic software solution like Docker, in order to prevent these mistakes from happening again.","title":"Issues and Learnings"},{"location":"business_case/","text":"Business Case Motivation Two familiar situations that probably everyone has experienced. First, you are at the supermarket and the cashier is scanning your products and everything is fine until he reaches the fruits and vegetables that you want to buy. He doesn't remember the PLU-codes and must either ask his colleagues for assistance or look up the codes on one of the countless pages with all PLU-codes. Or a different situation: You are waiting in line at the checkout and the person in front has forgotten that the store you are in doesn't weigh the fresh produce at checkout. So, the customer must rush back to the scale to weigh his goods. The result of both these situations is long waiting times, which nobody likes. To solve these problems, our group has developed an innovative idea called Grocery Vision. The idea behind Grocery Vision is to implement Artificial Intelligence at supermarket checkouts. Specifically, it involves the use of computer vision to detect fruits and vegetables, making the checkout process much easier for the cashier. Grocery Vision will be setup as follows\u2026 1.2. Setup Figure 1 displays the how Grocery Vision will be implemented in supermarkets. The camera is installed directly above the scale, so it can detect the fruits and vegetables that the cashier is weighing at that moment. After placing the fresh produce on the scale our model will detect which fruit or vegetable is currently being weighed. Once the model recognizes the correct item, it receives the input of the weight from the scale via the cashier software. Our model then automatically calculates the price which then appears on the cashier display. Since the hardware installed in a supermarket checkout has limited computing power, our model will run on a Jetson Nano, which will be part of the Grocery Vision solution. Figure 1: Setup of Grocery Vision in Supermarkets 1.3. Customer Relationship To determine Grocery Vision's customers and structure our business case, we used the Business Model Canvas framework. An overview of this framework can be seen in figure 2. Defining who our potential customers are, was the first question we needed to answer. At first it may seem obvious that the supermarket retailers are our main customers, as we plan to implement our Grocery Vision in supermarkets. However, as we are providing a product that needs to operate seamlessly with the already built-in hardware, the checkout counter, we also need to work together with the companies that build these checkout systems, which in our case are the POS-System providers ( POS = \"Point-of-Sale\"). Therefore, on the one hand we have the supermarket retailers as our direct customers and on the other hand the POS-System as strategic partners. Figure 2: Business Model Canvas The Grocery Vision solution will be distributed in form of a service bundle . This means once a supermarket purchases Grocery Vision it will receive hardware, the camera and Jetson Nano, as well as access to the digital platform. The digital platform allows supermarkets to receive updates over the Internet. For example, if the fruit and vegetable assortment changes or new products are offered in the supermarket, the stores will always have the newest version of our model. Instead of selling Grocery Vision through the usual distribution channels, our goal is to create a business ecosystem that co-creates value for all involved parties. Figure 3 displays the fundamental actors within this ecosystem. Access to the business ecosystem will be on a subscription basis. This means the supermarket will pay a fixed monthly fee which includes the usage of our hardware and grants them access to the digital platform. Supermarkets can not only download the latest versions of our model from the platform, but also choose which subscriptions they want to purchase. Figure 3: Business Ecosystem 1.4. Subscription options As the profit margins and product ranges of individual supermarkets vary, stores will be able to choose between different subscriptions. Figure 4 provides an overview of the subscription options available to supermarkets. The most simplistic version of our model will be the \" basic \" subscription. By choosing this option, the supermarket will receive both the hardware and access to the digital platform. While the model will still detect all the fruits and vegetables, the \"basic\" subscription will not be integrated into the cashier software. This means that it will only serve an informative purpose. It simply recognizes the items and informs the cashier which fruit or vegetable is being processed, saving him the trouble of looking up the PLU codes. As this subscription option does not require scale integration it is very simple to install. The \" premium \" subscription in contrast will require integration into the cashier software as it requires the input from the scale. This subscription option will also include the provision of hardware as well as access to the digital platform, however it will not only serve an informative purpose. Instead, it will combine the input from the scale with the object the camera detected to calculate the price. As this option is integrated into the cashier software the cashier does not need to take any further action. The \" ultimate \" subscription option entails a complete system integration. This means our solution will no longer be required to provide the hardware, because the POS-System Provider will build checkout systems with an integrated camera. Obviously, this option will not be eligible in the early stages of our development. However, once our solution has demonstrated its applicability, POS-System Providers could be incentivized to build systems with an integrated camera and enough computing power to run our models. Figure 4: Subscription Options 1.5. Competitor Analysis Today there are already few existing solutions that try to make shopping for groceries easier for customers and cashiers. In the following three cashierless alternatives are presented. First, there are Amazon Fresh/Go supermarkets that don't require any cashiers because there is no checkout process necessary. Instead, these stores are equipped with cameras that track every move a customer makes. The customer must create an account and log in at the entrance. Then he can just pick up the items from the shelf he wants to buy and walk out of the store. Although this concept seems very promising for the future it does have a big down-side. According to Forbes, it takes an average of about a million dollars in hardware costs alone to open one of these stores. While these stores could become reality in some major cities, it is impossible for most supermarkets in Germany to invest such a large sum. In addition, the need to create an Amazon account and the fact that every movement is tracked with facial recognition may deter some potential customers. Another alternative are self-checkout systems. More and more supermarkets are implementing these checkout systems as they do not require a cashier. While this proves beneficial from the supermarket operator's point of view, as it saves costs, it creates an additional effort for the customer. Moreover, it is often not possible to pay by cash which further lowers the acceptance of these checkouts. Furthermore, these systems are quite error-prone and often still require the attention of supermarket employees, thus eliminating their original benefit. Lastly, RFID-tags are another cashierless alternative. This solution requires all items in the store to be equipped with RFID-tags. When the customer is then ready to checkout, all items are placed in the checkout bin and the POS system recognizes the labels and calculates the price. While this is an attractive solution for retailers selling clothing or sportswear, it is less optimal for supermarkets, as every fruit or vegetable would need a RFID-tag. This would not only cause additional costs but also waste resources. 1.6. SWOT-Analysis Strengths Faster checkout and reduced waiting times for customers Reduced customer effort, as fresh produce is weighed at checkout Faster training of supermarket employees and reduced personnel costs Business ecosystem enables value co-creation for all involved parties Weaknesses Model prototype can currently only detect a small number of items \u2192 Creating a functioning model that detects all items could be difficult Innovations need to be fully matured in order to be implemented in this industry Opportunities Partnerships with POS-System providers could help create a more sophisticated solution by integrating the camera into checkout system Threats Cashiers could see their jobs existentially threatened \u2192 Protests through workers' unions Large supermarket chains have their own software development departments that greatly exceed our resources","title":"Business Case"},{"location":"business_case/#business-case","text":"","title":"Business Case"},{"location":"business_case/#motivation","text":"Two familiar situations that probably everyone has experienced. First, you are at the supermarket and the cashier is scanning your products and everything is fine until he reaches the fruits and vegetables that you want to buy. He doesn't remember the PLU-codes and must either ask his colleagues for assistance or look up the codes on one of the countless pages with all PLU-codes. Or a different situation: You are waiting in line at the checkout and the person in front has forgotten that the store you are in doesn't weigh the fresh produce at checkout. So, the customer must rush back to the scale to weigh his goods. The result of both these situations is long waiting times, which nobody likes. To solve these problems, our group has developed an innovative idea called Grocery Vision. The idea behind Grocery Vision is to implement Artificial Intelligence at supermarket checkouts. Specifically, it involves the use of computer vision to detect fruits and vegetables, making the checkout process much easier for the cashier. Grocery Vision will be setup as follows\u2026","title":"Motivation"},{"location":"business_case/#12-setup","text":"Figure 1 displays the how Grocery Vision will be implemented in supermarkets. The camera is installed directly above the scale, so it can detect the fruits and vegetables that the cashier is weighing at that moment. After placing the fresh produce on the scale our model will detect which fruit or vegetable is currently being weighed. Once the model recognizes the correct item, it receives the input of the weight from the scale via the cashier software. Our model then automatically calculates the price which then appears on the cashier display. Since the hardware installed in a supermarket checkout has limited computing power, our model will run on a Jetson Nano, which will be part of the Grocery Vision solution. Figure 1: Setup of Grocery Vision in Supermarkets","title":"1.2. Setup"},{"location":"business_case/#13-customer-relationship","text":"To determine Grocery Vision's customers and structure our business case, we used the Business Model Canvas framework. An overview of this framework can be seen in figure 2. Defining who our potential customers are, was the first question we needed to answer. At first it may seem obvious that the supermarket retailers are our main customers, as we plan to implement our Grocery Vision in supermarkets. However, as we are providing a product that needs to operate seamlessly with the already built-in hardware, the checkout counter, we also need to work together with the companies that build these checkout systems, which in our case are the POS-System providers ( POS = \"Point-of-Sale\"). Therefore, on the one hand we have the supermarket retailers as our direct customers and on the other hand the POS-System as strategic partners. Figure 2: Business Model Canvas The Grocery Vision solution will be distributed in form of a service bundle . This means once a supermarket purchases Grocery Vision it will receive hardware, the camera and Jetson Nano, as well as access to the digital platform. The digital platform allows supermarkets to receive updates over the Internet. For example, if the fruit and vegetable assortment changes or new products are offered in the supermarket, the stores will always have the newest version of our model. Instead of selling Grocery Vision through the usual distribution channels, our goal is to create a business ecosystem that co-creates value for all involved parties. Figure 3 displays the fundamental actors within this ecosystem. Access to the business ecosystem will be on a subscription basis. This means the supermarket will pay a fixed monthly fee which includes the usage of our hardware and grants them access to the digital platform. Supermarkets can not only download the latest versions of our model from the platform, but also choose which subscriptions they want to purchase. Figure 3: Business Ecosystem","title":"1.3. Customer Relationship"},{"location":"business_case/#14-subscription-options","text":"As the profit margins and product ranges of individual supermarkets vary, stores will be able to choose between different subscriptions. Figure 4 provides an overview of the subscription options available to supermarkets. The most simplistic version of our model will be the \" basic \" subscription. By choosing this option, the supermarket will receive both the hardware and access to the digital platform. While the model will still detect all the fruits and vegetables, the \"basic\" subscription will not be integrated into the cashier software. This means that it will only serve an informative purpose. It simply recognizes the items and informs the cashier which fruit or vegetable is being processed, saving him the trouble of looking up the PLU codes. As this subscription option does not require scale integration it is very simple to install. The \" premium \" subscription in contrast will require integration into the cashier software as it requires the input from the scale. This subscription option will also include the provision of hardware as well as access to the digital platform, however it will not only serve an informative purpose. Instead, it will combine the input from the scale with the object the camera detected to calculate the price. As this option is integrated into the cashier software the cashier does not need to take any further action. The \" ultimate \" subscription option entails a complete system integration. This means our solution will no longer be required to provide the hardware, because the POS-System Provider will build checkout systems with an integrated camera. Obviously, this option will not be eligible in the early stages of our development. However, once our solution has demonstrated its applicability, POS-System Providers could be incentivized to build systems with an integrated camera and enough computing power to run our models. Figure 4: Subscription Options","title":"1.4. Subscription options"},{"location":"business_case/#_1","text":"","title":""},{"location":"business_case/#15-competitor-analysis","text":"Today there are already few existing solutions that try to make shopping for groceries easier for customers and cashiers. In the following three cashierless alternatives are presented. First, there are Amazon Fresh/Go supermarkets that don't require any cashiers because there is no checkout process necessary. Instead, these stores are equipped with cameras that track every move a customer makes. The customer must create an account and log in at the entrance. Then he can just pick up the items from the shelf he wants to buy and walk out of the store. Although this concept seems very promising for the future it does have a big down-side. According to Forbes, it takes an average of about a million dollars in hardware costs alone to open one of these stores. While these stores could become reality in some major cities, it is impossible for most supermarkets in Germany to invest such a large sum. In addition, the need to create an Amazon account and the fact that every movement is tracked with facial recognition may deter some potential customers. Another alternative are self-checkout systems. More and more supermarkets are implementing these checkout systems as they do not require a cashier. While this proves beneficial from the supermarket operator's point of view, as it saves costs, it creates an additional effort for the customer. Moreover, it is often not possible to pay by cash which further lowers the acceptance of these checkouts. Furthermore, these systems are quite error-prone and often still require the attention of supermarket employees, thus eliminating their original benefit. Lastly, RFID-tags are another cashierless alternative. This solution requires all items in the store to be equipped with RFID-tags. When the customer is then ready to checkout, all items are placed in the checkout bin and the POS system recognizes the labels and calculates the price. While this is an attractive solution for retailers selling clothing or sportswear, it is less optimal for supermarkets, as every fruit or vegetable would need a RFID-tag. This would not only cause additional costs but also waste resources.","title":"1.5. Competitor Analysis"},{"location":"business_case/#16-swot-analysis","text":"Strengths Faster checkout and reduced waiting times for customers Reduced customer effort, as fresh produce is weighed at checkout Faster training of supermarket employees and reduced personnel costs Business ecosystem enables value co-creation for all involved parties Weaknesses Model prototype can currently only detect a small number of items \u2192 Creating a functioning model that detects all items could be difficult Innovations need to be fully matured in order to be implemented in this industry Opportunities Partnerships with POS-System providers could help create a more sophisticated solution by integrating the camera into checkout system Threats Cashiers could see their jobs existentially threatened \u2192 Protests through workers' unions Large supermarket chains have their own software development departments that greatly exceed our resources","title":"1.6. SWOT-Analysis"},{"location":"business_strategy/","text":"Business Strategy 2.1. Industry Expertise Since our group had no prior experience in the supermarket industry, we decided to reach out to different industry experts. Not only did we contact many supermarket and discounter chains, but also a variety of POS-System providers. To our advantage, we received a reply from Manfred Kiffe, the managing director of PROCOM iPOS Systems GmbH, who told us that he would be happy to share his 30 years of know-how with us. In preparation for this telephone interview, we decided to formulate some questions we would like to get answered: Presentation of our idea/solution In general, Mr. Kiffe found our idea very good, and he mentioned a few times that we should not be discouraged. Beforehand we sent him a demo video so that he could get a better understanding of how our solution works. His opinion was that we came up with an innovative idea that could have a lot of potential. He also said that he had contacts to innovative partners that he could put us in touch with and that we could also contact the development department of his company that programs the POS software. Furthermore, he also told us to keep him informed about the development of our project and to contact him again if we have any questions. Overall potential of our solution Mr. Kiffe believed our solution could be successful in the medium to long term. For large chains (Edeka, Rewe) our solution would be attractive if we have a low error rate in our model. He said that in the supermarket industry the margins are very low and really attention is paid to every possible saving. Therefore, our solution would be relevant for the big chains if we could actually present a cost benefit, such as staff savings in the long run. Possible difficulties for us that he had mentioned were, among others, that the big chains like Edeka already have their own internal software houses that research innovative ideas long in advance of the actual implementation. He said that POS-Systems have an average life span of about 7 years and the contracts with the POS-System manufacturers are made well in advance. As a second hurdle, he said that in his eyes \"banal\" innovations take a very long time to appear on the market and are then also partly taken off the market again due to too high error rates. As an example, he had mentioned the voice output at the cash register, which e.g., says out loud the amount of change for the hearing impaired. Or also that many stores have partially implemented the self-service checkout, but since with this too often still employees had to intervene, were dismantled again. For these reasons, he felt that it might take a very long time for our solution to appear on the market. Is our idea with the interface to the POS-Software and the scale at all feasible? Regarding the interface Mr. Kiffe shared a lot of valuable information. First, he told us that it is quite difficult to create an interface directly to the scale. In order to use the scale directly, we would need a certification in Germany, which is issued by the Federal Physical-Technical Office in Braunschweig. This process is very complex and not even all POS-System manufacturers have such a certification. He also informed us that there is a whole guide which describes what is allowed and what is not (Welmec-Guide). Additionally, in stores that have such a certification, every 2 years the calibration office comes by and looks whether the scale still measures accurately. As this process is quite complex some supermarkets, especially the smaller ones, have no integrated scales in the cash registers. This is then also the reason why in some supermarkets customers must weigh the fresh goods themselves, as these stores do not have checkout systems with integrated scales. Therefore, he said that it is theoretically possible for us to create such an interface directly to the scale, but it could be associated with a lot of work. Instead, he presented a clever alternative. He said we could bypass this certification process if we do not create the interface directly to the scale, but to the POS software, which already has the certification in the ideal case. Would an integration of our solution into existing POS-Systems be at all possible? For the integration, Mr. Kiffe was of the opinion that it would make more sense in the first step to decouple the camera software and POS-System software, since this would avoid complications with the different operating systems. As a second step, or long-term solution, he said a direct integration into the POS system would be the optimal solution. However, this would require the POS-System provider to manufacture a system with an integrated camera. Do the POS-Systems have a GPU that would be capable of running a machine learning model? Mr. Kiffe said that the absolute top model has an i5 processor. However, this is not the standard. He informed us that most POS-Systems have an Intel J1900 or i3 processor. Therefore, GPU performance is very low. He also said that processes that are taken for granted by customers, such as contactless payments, sometimes push the POS system to the limit, since the WIFI connection in the stores is often not outstanding. On a side note, he also mentioned that a scanner scale costs about 2000\u20ac and the associated cash POS-System another 2000\u20ac. This means that if a supermarket has several cash registers, this is a very large investment, especially for the smaller stores. 2.2. Learnings With the help of our expert interview, we were able to gain many insights. The interview enlightened us that some of our original ideas were good in theory, but not feasible in practice. Initially, we planned to run our model either via a cloud-based platform or via the hardware of the POS system. However, we were told otherwise: firstly, the Internet connection would not be strong enough to run a cloud-based platform, and secondly, the built-in hardware would not be able to run our model. 2.3. Benefits We want to conclude the business case with the gains that our application brings to the different business ecosystem participants. Our service has several benefits that can be attributed to the different players in the business platform we have created. Let's first take a look at the supermarkets. Since they are the main customers or users of our supermarkets, they are the focus. In supermarkets, it is much easier to train new employees and the time required to do so can be shortened. This means that employees are ready to work faster, make fewer mistakes, especially in the initial phase, and therefore have higher productivity. And consequently, this leads to a reduction in personnel costs. Another actor we have already introduced is the supermarket visitor or customer. The actual supermarket visitor or customer can go through the checkout faster and does not have to scan or weigh their products themselves. Compared to other checkout systems, this is a significant advantage and the customer experiences a much faster checkout. simply a simpler customer journey. And finally with the last of the 3 players in our business ecosystem, the POS system provider. The POS system provider that would benefit from an integration of our service to have a clear advantage over their competitors with a sophisticated POS system. The main advantage is that the purchase of products can be handled without labeling or PLU codes. And the additional point is that it can easily adapt to changes in the product range. 2.4. Future Business strategy We had a very interesting meeting with an industry expert, Mr. Kiffe, who is the CEO of Procom AG. He basically tipped us off that we could develop our company in two ways. Figure 5: Future Business Strategy In the first phase, we built an initial prototype for the detection of selected fruits and vegetables. As we continue our dynamic development cycle with constant improvements, we will expand the service to all supermarket products Pilot projects in various smaller grocery stores After these steps, we could decide on a direction where we would integrate our solution into a checkout system of the major discounters in Germany The other path would put our focus on business development and expanding the customer base of smaller supermarkets 2.5. Overall Learnings We learned a lot on our project journey and would like to share some important lessons with you. First of all, everything takes time and even if the tasks seem smaller, just plan some extra time. Another insight is that you should keep building the project over time. Problems and difficulties will arise, so don't be naive and just take that into account. Finally, talk to industry experts, as they can give you important insights and a different perspective.","title":"Business Strategy"},{"location":"business_strategy/#business-strategy","text":"","title":"Business Strategy"},{"location":"business_strategy/#21-industry-expertise","text":"Since our group had no prior experience in the supermarket industry, we decided to reach out to different industry experts. Not only did we contact many supermarket and discounter chains, but also a variety of POS-System providers. To our advantage, we received a reply from Manfred Kiffe, the managing director of PROCOM iPOS Systems GmbH, who told us that he would be happy to share his 30 years of know-how with us. In preparation for this telephone interview, we decided to formulate some questions we would like to get answered: Presentation of our idea/solution In general, Mr. Kiffe found our idea very good, and he mentioned a few times that we should not be discouraged. Beforehand we sent him a demo video so that he could get a better understanding of how our solution works. His opinion was that we came up with an innovative idea that could have a lot of potential. He also said that he had contacts to innovative partners that he could put us in touch with and that we could also contact the development department of his company that programs the POS software. Furthermore, he also told us to keep him informed about the development of our project and to contact him again if we have any questions. Overall potential of our solution Mr. Kiffe believed our solution could be successful in the medium to long term. For large chains (Edeka, Rewe) our solution would be attractive if we have a low error rate in our model. He said that in the supermarket industry the margins are very low and really attention is paid to every possible saving. Therefore, our solution would be relevant for the big chains if we could actually present a cost benefit, such as staff savings in the long run. Possible difficulties for us that he had mentioned were, among others, that the big chains like Edeka already have their own internal software houses that research innovative ideas long in advance of the actual implementation. He said that POS-Systems have an average life span of about 7 years and the contracts with the POS-System manufacturers are made well in advance. As a second hurdle, he said that in his eyes \"banal\" innovations take a very long time to appear on the market and are then also partly taken off the market again due to too high error rates. As an example, he had mentioned the voice output at the cash register, which e.g., says out loud the amount of change for the hearing impaired. Or also that many stores have partially implemented the self-service checkout, but since with this too often still employees had to intervene, were dismantled again. For these reasons, he felt that it might take a very long time for our solution to appear on the market. Is our idea with the interface to the POS-Software and the scale at all feasible? Regarding the interface Mr. Kiffe shared a lot of valuable information. First, he told us that it is quite difficult to create an interface directly to the scale. In order to use the scale directly, we would need a certification in Germany, which is issued by the Federal Physical-Technical Office in Braunschweig. This process is very complex and not even all POS-System manufacturers have such a certification. He also informed us that there is a whole guide which describes what is allowed and what is not (Welmec-Guide). Additionally, in stores that have such a certification, every 2 years the calibration office comes by and looks whether the scale still measures accurately. As this process is quite complex some supermarkets, especially the smaller ones, have no integrated scales in the cash registers. This is then also the reason why in some supermarkets customers must weigh the fresh goods themselves, as these stores do not have checkout systems with integrated scales. Therefore, he said that it is theoretically possible for us to create such an interface directly to the scale, but it could be associated with a lot of work. Instead, he presented a clever alternative. He said we could bypass this certification process if we do not create the interface directly to the scale, but to the POS software, which already has the certification in the ideal case. Would an integration of our solution into existing POS-Systems be at all possible? For the integration, Mr. Kiffe was of the opinion that it would make more sense in the first step to decouple the camera software and POS-System software, since this would avoid complications with the different operating systems. As a second step, or long-term solution, he said a direct integration into the POS system would be the optimal solution. However, this would require the POS-System provider to manufacture a system with an integrated camera. Do the POS-Systems have a GPU that would be capable of running a machine learning model? Mr. Kiffe said that the absolute top model has an i5 processor. However, this is not the standard. He informed us that most POS-Systems have an Intel J1900 or i3 processor. Therefore, GPU performance is very low. He also said that processes that are taken for granted by customers, such as contactless payments, sometimes push the POS system to the limit, since the WIFI connection in the stores is often not outstanding. On a side note, he also mentioned that a scanner scale costs about 2000\u20ac and the associated cash POS-System another 2000\u20ac. This means that if a supermarket has several cash registers, this is a very large investment, especially for the smaller stores.","title":"2.1. Industry Expertise"},{"location":"business_strategy/#22-learnings","text":"With the help of our expert interview, we were able to gain many insights. The interview enlightened us that some of our original ideas were good in theory, but not feasible in practice. Initially, we planned to run our model either via a cloud-based platform or via the hardware of the POS system. However, we were told otherwise: firstly, the Internet connection would not be strong enough to run a cloud-based platform, and secondly, the built-in hardware would not be able to run our model.","title":"2.2. Learnings"},{"location":"business_strategy/#23-benefits","text":"We want to conclude the business case with the gains that our application brings to the different business ecosystem participants. Our service has several benefits that can be attributed to the different players in the business platform we have created. Let's first take a look at the supermarkets. Since they are the main customers or users of our supermarkets, they are the focus. In supermarkets, it is much easier to train new employees and the time required to do so can be shortened. This means that employees are ready to work faster, make fewer mistakes, especially in the initial phase, and therefore have higher productivity. And consequently, this leads to a reduction in personnel costs. Another actor we have already introduced is the supermarket visitor or customer. The actual supermarket visitor or customer can go through the checkout faster and does not have to scan or weigh their products themselves. Compared to other checkout systems, this is a significant advantage and the customer experiences a much faster checkout. simply a simpler customer journey. And finally with the last of the 3 players in our business ecosystem, the POS system provider. The POS system provider that would benefit from an integration of our service to have a clear advantage over their competitors with a sophisticated POS system. The main advantage is that the purchase of products can be handled without labeling or PLU codes. And the additional point is that it can easily adapt to changes in the product range.","title":"2.3. Benefits"},{"location":"business_strategy/#24-future-business-strategy","text":"We had a very interesting meeting with an industry expert, Mr. Kiffe, who is the CEO of Procom AG. He basically tipped us off that we could develop our company in two ways. Figure 5: Future Business Strategy In the first phase, we built an initial prototype for the detection of selected fruits and vegetables. As we continue our dynamic development cycle with constant improvements, we will expand the service to all supermarket products Pilot projects in various smaller grocery stores After these steps, we could decide on a direction where we would integrate our solution into a checkout system of the major discounters in Germany The other path would put our focus on business development and expanding the customer base of smaller supermarkets","title":"2.4. Future Business strategy"},{"location":"business_strategy/#25-overall-learnings","text":"We learned a lot on our project journey and would like to share some important lessons with you. First of all, everything takes time and even if the tasks seem smaller, just plan some extra time. Another insight is that you should keep building the project over time. Problems and difficulties will arise, so don't be naive and just take that into account. Finally, talk to industry experts, as they can give you important insights and a different perspective.","title":"2.5. Overall Learnings"},{"location":"data/","text":"Data Generation To gather sufficient data for training, we decided to create the data synthetically. Synthetic generation of training data allows us to create a large amount of data in a short time and allows for fast adaptability to new vegetables and fruits. Also, annotations can be stored at the same time as the picture is created. It is not necessary to manually label the pictures. Data Creation For the realization of our proof-of-concept we decided to use a limited number of vegetables and fruits. The concept of creating synthetic data relies on using a random picture and printing the items that the model must detect on them. In our case, one of 60 random background images served as the basis for the synthetic images. Since more than thousand images must be created for our training, 60 background images did not provide enough variety. Our initial tries revealed that adding additional noise to the background of the image improved the models accuracy. Therefore, we added another step that modifies the background before placing the fruit and vegetable items on the background. We made use of a collection of random objects such as cars, screwdrivers, chairs, etc. which were randomly placed on the background. We also made sure to add hands to our collection of noise items. Adding a high number of noise items to the background ensures that the background of each image is unique. We limited the model to recognize only a handful of fruits and vegetables: Eggplant, Avocado, Cucumber, Sweet Potato and Lemon. Eggplant Avocado Cucumber Sweet Potato Lemon We took 30 to 40 pictures for each vegetable and fruit class. Most of the pictures were taken by us. In a second step, we used an image editing program to cut out the individual objects to get rid of the background. Some images were used from the \"Fruits360\" Dataset from Kaggle.com. The cut-out elements were then randomly placed on the background images after applying modifying the background with noise items. To improve the class predictions of our model, we randomly rotate and resize each object before placing it on to the picture. We also allow overlapping of up to 10%. Overlapping ensures that the model recognizes the vegetables early, even if there are still hands covering the vegetables or fruits or the vegetables and fruits cover each other to a certain degree. Our final images that we used to train our model had about 1-5 vegetable and fruit objects. The images we used to create our synthetic data can be accessed here: drive.google.com/drive/folders/1I6pUovgsugu6mKjATuBTfGWS__Y3UDxg?usp=sharing Label Making The location of an item plotted on the image is randomly chosen and stored to a text file at the same time. Since we are training a Yolo model, the format in which class and location information is stored to the corresponding conventions. Our final dataset By creating synthetic images, we can assume that we have avoided making man-made errors like grouping, positioning or selection are bypassed. However, we cannot exclude that our generated images are not completely unbiased. The way we captured images and cropped the objects is a key element for creating our data. Errors on this level can have a strong impact on the synthetically generated images. Our final dataset consisted of 7000 images which we split into 80% training data and 20% test data. Possible Extensions Introducing new objects Introducing new elements is a challenge for our model. To add new objects to the model we recommend transfer learning. This is done by transferring the learning progress of the existing model to the new one. This results in advantages such as faster creation, better model quality and less resource usage. Improving the model Furthermore, our model can be improved by active learning. In active learning mode, every object recognition that is not recalled by the cashier is perceived as correct. Any object recognition that is recalled by the cashier is perceived as false. This mode requires special attention from the cashiers. However, if our system is used in large supermarket chains, the effort would be very limited, due to having only a few cashiers work in active learning mode for only a few hours creates large amount of data. The amount of additional training data that would be generated would quickly improve the models with little effort. Learnings Background Noise We started generating our data by not adding additional noise items on to the background before adding the objects that must be detected by the model. Creating data that way does not deliver enough variety in the background of the picture and results in a model that does not perform well. Our intention when adding random noise objects on the pictures is to create a unique looking background for each photo. Adding additional noise items improved our model quality. Cut Out Cropping out images is error prone. Most of us used the \"Preview\"-App from the Mac to cut out the objects from the original picture. The \"Preview\"-App offers different tools for that task. There are two main features that we used: Intelligent Lasso The intelligent Lasso helps the user to cut out objects, by only having to draw a rough outline around the object. Magic wand The magic wand works color based. The user has to set a start point on the picture and the software adds pixels to the mask based on the degree that the user defines. Although the magic wand is the easier tool to use, it causes problems. We noticed that often pixels far outside of the actual objects are also added to the mask (See binary mask on the right side). Since it was mostly just a few pixels and not a larger area we did not see it at first and came across this issue at a very late stage of the project. The problem that that imposes is that bounding box is drawn to big and the model quality is reduced. (See picture on the right) Image variety As for everything in machine learning, it is true that the model is only as good as the data that is used for training. We started with only a few images per class and quickly noticed that there was not enough variety in the original images of objects that we created for generating our data. Initially we had a red bell pepper in our data set. For the red bell pepper, we used images from the fruit360 dataset from Kaggle. Since all these bell pepper pictures had a white reflection somewhere on the skin, the resulting model detected a lot more bell peppers, when not tested on our synthetic data. Either way, we did not include bell pepper in the model.","title":"Data"},{"location":"data/#data-generation","text":"To gather sufficient data for training, we decided to create the data synthetically. Synthetic generation of training data allows us to create a large amount of data in a short time and allows for fast adaptability to new vegetables and fruits. Also, annotations can be stored at the same time as the picture is created. It is not necessary to manually label the pictures.","title":"Data Generation"},{"location":"data/#data-creation","text":"For the realization of our proof-of-concept we decided to use a limited number of vegetables and fruits. The concept of creating synthetic data relies on using a random picture and printing the items that the model must detect on them. In our case, one of 60 random background images served as the basis for the synthetic images. Since more than thousand images must be created for our training, 60 background images did not provide enough variety. Our initial tries revealed that adding additional noise to the background of the image improved the models accuracy. Therefore, we added another step that modifies the background before placing the fruit and vegetable items on the background. We made use of a collection of random objects such as cars, screwdrivers, chairs, etc. which were randomly placed on the background. We also made sure to add hands to our collection of noise items. Adding a high number of noise items to the background ensures that the background of each image is unique. We limited the model to recognize only a handful of fruits and vegetables: Eggplant, Avocado, Cucumber, Sweet Potato and Lemon. Eggplant Avocado Cucumber Sweet Potato Lemon We took 30 to 40 pictures for each vegetable and fruit class. Most of the pictures were taken by us. In a second step, we used an image editing program to cut out the individual objects to get rid of the background. Some images were used from the \"Fruits360\" Dataset from Kaggle.com. The cut-out elements were then randomly placed on the background images after applying modifying the background with noise items. To improve the class predictions of our model, we randomly rotate and resize each object before placing it on to the picture. We also allow overlapping of up to 10%. Overlapping ensures that the model recognizes the vegetables early, even if there are still hands covering the vegetables or fruits or the vegetables and fruits cover each other to a certain degree. Our final images that we used to train our model had about 1-5 vegetable and fruit objects. The images we used to create our synthetic data can be accessed here: drive.google.com/drive/folders/1I6pUovgsugu6mKjATuBTfGWS__Y3UDxg?usp=sharing","title":"Data Creation"},{"location":"data/#label-making","text":"The location of an item plotted on the image is randomly chosen and stored to a text file at the same time. Since we are training a Yolo model, the format in which class and location information is stored to the corresponding conventions.","title":"Label Making"},{"location":"data/#our-final-dataset","text":"By creating synthetic images, we can assume that we have avoided making man-made errors like grouping, positioning or selection are bypassed. However, we cannot exclude that our generated images are not completely unbiased. The way we captured images and cropped the objects is a key element for creating our data. Errors on this level can have a strong impact on the synthetically generated images. Our final dataset consisted of 7000 images which we split into 80% training data and 20% test data.","title":"Our final dataset"},{"location":"data/#possible-extensions","text":"Introducing new objects Introducing new elements is a challenge for our model. To add new objects to the model we recommend transfer learning. This is done by transferring the learning progress of the existing model to the new one. This results in advantages such as faster creation, better model quality and less resource usage. Improving the model Furthermore, our model can be improved by active learning. In active learning mode, every object recognition that is not recalled by the cashier is perceived as correct. Any object recognition that is recalled by the cashier is perceived as false. This mode requires special attention from the cashiers. However, if our system is used in large supermarket chains, the effort would be very limited, due to having only a few cashiers work in active learning mode for only a few hours creates large amount of data. The amount of additional training data that would be generated would quickly improve the models with little effort.","title":"Possible Extensions"},{"location":"data/#learnings","text":"Background Noise We started generating our data by not adding additional noise items on to the background before adding the objects that must be detected by the model. Creating data that way does not deliver enough variety in the background of the picture and results in a model that does not perform well. Our intention when adding random noise objects on the pictures is to create a unique looking background for each photo. Adding additional noise items improved our model quality. Cut Out Cropping out images is error prone. Most of us used the \"Preview\"-App from the Mac to cut out the objects from the original picture. The \"Preview\"-App offers different tools for that task. There are two main features that we used: Intelligent Lasso The intelligent Lasso helps the user to cut out objects, by only having to draw a rough outline around the object. Magic wand The magic wand works color based. The user has to set a start point on the picture and the software adds pixels to the mask based on the degree that the user defines. Although the magic wand is the easier tool to use, it causes problems. We noticed that often pixels far outside of the actual objects are also added to the mask (See binary mask on the right side). Since it was mostly just a few pixels and not a larger area we did not see it at first and came across this issue at a very late stage of the project. The problem that that imposes is that bounding box is drawn to big and the model quality is reduced. (See picture on the right) Image variety As for everything in machine learning, it is true that the model is only as good as the data that is used for training. We started with only a few images per class and quickly noticed that there was not enough variety in the original images of objects that we created for generating our data. Initially we had a red bell pepper in our data set. For the red bell pepper, we used images from the fruit360 dataset from Kaggle. Since all these bell pepper pictures had a white reflection somewhere on the skin, the resulting model detected a lot more bell peppers, when not tested on our synthetic data. Either way, we did not include bell pepper in the model.","title":"Learnings"},{"location":"model/","text":"Model Requirements Our model imposes technical requirements: It must be able to recognize multiple classes It must run in real time It must be small enough to run on the Jetson Nano To measure the quality of our model, we did not focus solely on metrics but rather on satisfying the following use case: A person brings one or more fruit and/or vegetable objects to be recognized into the image. The objects are included in the POS system if the objects are recognized by the model over a certain time period t with a certain probability p. As for specific values we set our goal to achieve a probability of over p = 0.85 for over t = one second to add the detected object to the POS System. If our model does not make any mistakes during the process of a simulated purchase process, we would consider our quality requirement as satisfied. 1. Model Out of the many object detection algorithms, we decided to use the YOLO framework after research. Yolo is based on a CNN structure and detects objects in real time. Because of the CNN structure, the algorithm requires only a single forward propagation in the neural network to detect objects. Furthermore, Yolo detects multiple classes and their bounding boxes simultaneously. The YOLO Framework offers a variety of advantages: Speed: The algorithms can predict objects in real-time. High accuracy: YOLO is a predictive technique that provides accurate results with minimal background errors. Learning capabilities: The algorithm has learning capabilities that enable it to learn the representations of objects and apply them in object detection. 1. Training We trained our model with google Colab. https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb#scrollTo=eaFNnxLJbq4J Of the different model sizes, we opted for the smallest Yolo5n. We found a batch size of 16 and an era size of 50 to be sufficient","title":"Model"},{"location":"model/#model","text":"","title":"Model"},{"location":"model/#requirements","text":"Our model imposes technical requirements: It must be able to recognize multiple classes It must run in real time It must be small enough to run on the Jetson Nano To measure the quality of our model, we did not focus solely on metrics but rather on satisfying the following use case: A person brings one or more fruit and/or vegetable objects to be recognized into the image. The objects are included in the POS system if the objects are recognized by the model over a certain time period t with a certain probability p. As for specific values we set our goal to achieve a probability of over p = 0.85 for over t = one second to add the detected object to the POS System. If our model does not make any mistakes during the process of a simulated purchase process, we would consider our quality requirement as satisfied. 1.","title":"Requirements"},{"location":"model/#model_1","text":"Out of the many object detection algorithms, we decided to use the YOLO framework after research. Yolo is based on a CNN structure and detects objects in real time. Because of the CNN structure, the algorithm requires only a single forward propagation in the neural network to detect objects. Furthermore, Yolo detects multiple classes and their bounding boxes simultaneously. The YOLO Framework offers a variety of advantages: Speed: The algorithms can predict objects in real-time. High accuracy: YOLO is a predictive technique that provides accurate results with minimal background errors. Learning capabilities: The algorithm has learning capabilities that enable it to learn the representations of objects and apply them in object detection. 1.","title":"Model"},{"location":"model/#training","text":"We trained our model with google Colab. https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb#scrollTo=eaFNnxLJbq4J Of the different model sizes, we opted for the smallest Yolo5n. We found a batch size of 16 and an era size of 50 to be sufficient","title":"Training"},{"location":"team/","text":"The Project Team As some may have noticed, we did this together as a team, but who is on this \"team\"? Our team consists of 5 students from KIT who are all studying industrial engineering in the master's program and actually all started studying at the same time. But let's briefly introduce all of them individually. Christian Ohmstedt Mario Marin-Fellger Nils Ness Philipp Sch\u00f6nlaub Janik K\u00f6nigshofer","title":"Team"},{"location":"team/#the-project-team","text":"As some may have noticed, we did this together as a team, but who is on this \"team\"? Our team consists of 5 students from KIT who are all studying industrial engineering in the master's program and actually all started studying at the same time. But let's briefly introduce all of them individually.","title":"The Project Team"},{"location":"team/#christian-ohmstedt","text":"","title":"Christian Ohmstedt"},{"location":"team/#mario-marin-fellger","text":"","title":"Mario Marin-Fellger"},{"location":"team/#nils-ness","text":"","title":"Nils Ness"},{"location":"team/#philipp-schonlaub","text":"","title":"Philipp Sch\u00f6nlaub"},{"location":"team/#janik-konigshofer","text":"","title":"Janik K\u00f6nigshofer"},{"location":"user_expert_servey/","text":"Serveys As an integral part of our Project we did a small servey with different actours in our business plan. In the following Chapter we show some very interesting answers to a individualized questionaire we designed for our Project. The Expert Interview In the Beginning of our Project we reached out to several important actors for our use case. One of these actors are the Production Companies of Cashieir systems in the German market. Through an interview with the managing director of abc GmbH we could draw decisive conclusions on our project. The original completed questionnaire can be looked up here","title":"Surveys"},{"location":"user_expert_servey/#serveys","text":"As an integral part of our Project we did a small servey with different actours in our business plan. In the following Chapter we show some very interesting answers to a individualized questionaire we designed for our Project.","title":"Serveys"},{"location":"user_expert_servey/#the-expert-interview","text":"In the Beginning of our Project we reached out to several important actors for our use case. One of these actors are the Production Companies of Cashieir systems in the German market. Through an interview with the managing director of abc GmbH we could draw decisive conclusions on our project. The original completed questionnaire can be looked up here","title":"The Expert Interview"}]}